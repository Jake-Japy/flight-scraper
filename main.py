from fastapi import FastAPI, Depends, HTTPException
from sqlalchemy import create_engine, Column, Integer, String, DateTime
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, Session
from pydantic import BaseModel
from datetime import datetime
import requests
from bs4 import BeautifulSoup
from celery import Celery
from models import Flight
import redis
import json
import uuid
import logging
from tenacity import retry, stop_after_attempt, wait_fixed

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

app = FastAPI()

# Initialize the SQLite database (Using SQLite because it is lightweight and requires minimal set up)
SQLALCHEMY_DATABASE_URL = "sqlite:///./flight_data.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# Set up a redis client
try:
    redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
    redis_client.ping()
except redis.ConnectionError as e:
    logger.warning(f"Redis connection failed: {e}. Proceeding without cache.")
    redis_client = None

# Set up the celery queue for task queueing
celery = Celery('tasks', broker='redis://localhost:6379/0', backend='redis://localhost:6379/0')
celery.conf.update(task_track_started=True)


Base.metadata.create_all(bind=engine)


# Pydantic model used for type safety on generating requests to prevent user errors or possible type error conversions
class FlightRequest(BaseModel):
    airline_code: str
    flight_number: str
    departure_date: str  # Format: YYYY-MM-DD


# Pydantic model used to enforce likely response types generated by the request. Needed to ensure database type
# compliance. Could potentially look at an unstructured data type in future to remove the need for type compliance.
class FlightResponse(BaseModel):
    flight_id: str
    airline_code: str
    flight_number: str
    departure_date: str
    departure_airport: str
    arrival_airport: str
    departure_time: str
    arrival_time: str
    status: str
    gate: str | None


def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# A decorator needed to alter the request to attempt a retry
@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
def make_request(url, headers):
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    return response


# Celery task decorator to create the scraping task through scrapy.
@celery.task
def scrape_flight_data(airline_code: str, flight_number: str, departure_date: str):
    logger.debug(f"Scraping flight {airline_code}{flight_number} for {departure_date}")
    url = f"https://www.flightstats.com/v2/flight-tracker/{airline_code}/{flight_number}?year={departure_date[:4]}&month={departure_date[5:7]}&date={departure_date[8:10]}"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    # Below I attempt to contact the server and generate a response that I can use to build the data.
    try:
        response = make_request(url, headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        try:
            flight_no_elem = soup.find("div", class_=lambda x: x and "FlightNumberContainer" in x)
            flight_no = flight_no_elem.get_text().strip() if flight_no_elem else f"{airline_code}{flight_number}"
        except Exception as e:
            logger.warning(f"Failed to extract flight number: {e}")
            flight_no = f"{airline_code}{flight_number}"

        try:
            airport_names = soup.find_all("div", class_=lambda x: x and "TextHelper" in x and "CPamx" in x)
            airports = [name.get_text().strip() for name in airport_names[:2]] if airport_names else ["N/A", "N/A"]
        except Exception as e:
            logger.warning(f"Failed to extract airports: {e}")
            airports = ["N/A", "N/A"]

        try:
            status_elements = soup.find_all("div", class_=lambda x: x and "TextHelper" in x and "bcmzUJ" in x)
            status = status_elements[0].get_text().strip() if status_elements else "N/A"
        except Exception as e:
            logger.warning(f"Failed to extract status: {e}")
            status = "N/A"

        try:
            time_elements = soup.find_all("div", class_=lambda x: x and "TextHelper" in x and "cCfBRT" in x)
            departure_time = time_elements[0].get_text().strip() if time_elements else "N/A"
            arrival_time = time_elements[1].get_text().strip() if len(time_elements) > 1 else "N/A"
        except Exception as e:
            logger.warning(f"Failed to extract times: {e}")
            departure_time = arrival_time = "N/A"

        try:
            gate_values = soup.find_all("div", class_=lambda x: x and "TGBValue" in x)
            gate = gate_values[0].get_text().strip() if gate_values else None
        except Exception as e:
            logger.warning(f"Failed to extract gate: {e}")
            gate = None

        # Convert departure_date to datetime
        try:
            parsed_date = datetime.strptime(departure_date, "%Y-%m-%d")
        except ValueError as e:
            logger.error(f"Invalid departure date format: {e}")
            return {"error": f"Invalid departure date format: {departure_date}"}

        flight_data = {
            "flight_id": str(uuid.uuid4()),
            "airline_code": airline_code,
            "flight_number": flight_number,
            "departure_date": parsed_date,
            "departure_airport": airports[0],
            "arrival_airport": airports[1],
            "departure_time": departure_time,
            "arrival_time": arrival_time,
            "status": status,
            "gate": gate
        }

        # Check if flight data is mostly empty
        if all(v in ["N/A", None] for k, v in flight_data.items() if
               k not in ["flight_id", "airline_code", "flight_number", "departure_date"]):
            logger.warning(f"No valid flight data found for {airline_code}{flight_number} on {departure_date}")
            return {"error": f"No flight data available for {airline_code}{flight_number} on {departure_date}"}

        # Save to database
        db = SessionLocal()
        try:
            db_flight = Flight(**flight_data)
            db.add(db_flight)
            db.commit()
            db.refresh(db_flight)
        except Exception as e:
            logger.error(f"Database error: {e}")
            raise
        finally:
            db.close()

        # Cache the result if Redis is available
        if redis_client:
            try:
                redis_client.setex(f"flight:{airline_code}:{flight_number}:{departure_date}", 3600,
                                   json.dumps(flight_data))
            except redis.ConnectionError:
                logger.warning("Failed to cache in Redis, proceeding without cache.")

        logger.debug(f"Successfully scraped and stored flight {airline_code}{flight_number}")
        return flight_data

    except requests.HTTPError as e:
        logger.error(f"HTTP error for {url}: {str(e)}")
        return {"error": f"Failed to fetch flight data: {str(e)}"}
    except Exception as e:
        logger.error(f"Scraping error for {url}: {str(e)}")
        return {"error": f"Failed to parse flight data: {str(e)}"}


# API endpoint
@app.get("/flights/", response_model=FlightResponse)
async def get_flight_info(airline_code: str, flight_number: str, departure_date: str, db: Session = Depends(get_db)):
    # Validate departure_date format must be in a year month day format - I might need to consider some alternatives for
    # the American way of inputting dates in month day year format
    try:
        datetime.strptime(departure_date, "%Y-%m-%d")
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid date format. Use YYYY-MM-DD")

    # check that redis is accepting connections (if not check port number / or if it is running)
    cache_key = f"flight:{airline_code}:{flight_number}:{departure_date}"
    cached_data = None
    if redis_client:
        try:
            cached_data = redis_client.get(cache_key)
            if cached_data:
                logger.debug(f"Cache hit for {cache_key}")
                return json.loads(cached_data)
        except redis.ConnectionError:
            logger.warning("Redis unavailable, skipping cache.")

    flight = db.query(Flight).filter(
        Flight.airline_code == airline_code,
        Flight.flight_number == flight_number,
        Flight.departure_date == departure_date
    ).first()

    if flight:
        flight_data = {
            "flight_id": flight.flight_id,
            "airline_code": flight.airline_code,
            "flight_number": flight.flight_number,
            "departure_date": flight.departure_date.strftime("%Y-%m-%d"),
            "departure_airport": flight.departure_airport,
            "arrival_airport": flight.arrival_airport,
            "departure_time": flight.departure_time,
            "arrival_time": flight.arrival_time,
            "status": flight.status,
            "gate": flight.gate
        }
        if redis_client:
            try:
                redis_client.setex(cache_key, 3600, json.dumps(flight_data))
            except redis.ConnectionError:
                logger.warning("Failed to cache in Redis, proceeding without cache.")
        logger.debug(f"Database hit for {cache_key}")
        return flight_data

    # Creates the task that gets pushed into the celery queue
    logger.debug(f"Starting Celery task for {airline_code}{flight_number} on {departure_date}")
    try:
        task = scrape_flight_data.delay(airline_code, flight_number, departure_date)
        result = task.get(timeout=30)
        if "error" in result:
            logger.error(f"Celery task returned error: {result['error']}")
            raise HTTPException(status_code=404, detail=f"Flight data retrieval failed: {result['error']}")
        return result
    except Exception as e:
        logger.error(f"Celery task failed: {str(e)}")
        # if celery is malfunctioning for some reason this will allow the scraping to occur without it being queued.
        # if this step fails while you are attempting multiple requests it could cause requests to be missed or issues
        # with the synchronicity of your requests. It is advisable you run this with celery enabled and running.
        logger.info("Falling back to direct scraping due to Celery failure")
        result = scrape_flight_data(airline_code, flight_number, departure_date)
        if "error" in result:
            logger.error(f"Direct scraping failed: {result['error']}")
            raise HTTPException(status_code=404, detail=f"Flight data retrieval failed: {result['error']}")
        return result